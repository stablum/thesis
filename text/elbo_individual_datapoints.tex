\section{Variational Lower Bound as sum of terms dependent on individual datapoints}

As used by \cite{1312.6114}, the variational lower bound can be decomposed into
a sum of terms, each dependent only on an individual datapoint. 
This follows the assumption that each datapoint generated by a certain
latent variable realization is independent from both the other datapoints:
\begin{nalign}
\pXcond = \prod_{i=1}^N \pxicondi
\end{nalign}

Same assumption is made on the prior distribution on the latent variables:
\begin{nalign}
\pZ = \prod_{i=1}^N \pzi
\end{nalign}

Hence this is the form for the joint probability:
\begin{nalign}
\pXZ = \pXcond \pZ &= \prod_{i=1}^N \pxicondi \pzi = \prod_{i=1}^N \pxizi
\end{nalign}

For convenience, the chosen form for $\elboX$
will be the $\ref{elbo_crossentropy}$.

It's possible to make use of information-theoretical properties
\cite{Bergstrom2008}:

\begin{nalign}
\entropy{\qphiZ} &= \entropy{\qphizone} + \entropy{\qphiZminusone | \qphizone} 
&& \text{chain rule for joint entropy}\\
 &= \entropy{\qphizone} + \entropy{\qphiZminusone}
&& \text{independence of datapoints}\\
&= \sum_i \qphizi && \text{recursion}
\end{nalign}



By plugging these forms into the variational lower bound:
\begin{nalign}
\elboX = blablablaentropywithindividualdatapoints FIXME
\end{nalign}
