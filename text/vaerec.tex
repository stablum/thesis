\section{VAERec}

VAERec is one of the contributions of this thesis.
It extends the AutoRec model making use of the VAE framework.

It has been implemented in three variants:

\paragraph{U-VAERec} 
reconstructs user rows by learning the conditional distribution
$\ptheta{\ric|\boldui}$ assumed to be a diagonal-covariance Gaussian
and, jointly, the variational approximation to the posterior
$\qphi{\boldui|\ric}$, also assumed to be a diagonal-covariance Gaussian.

\paragraph{I-VAERec} does the same as \emph{U-VAERec}, 
but with item columns, learning $\ptheta{\rcj|\boldvj}$
and $\qphi{\boldvj|\rcj}$.

\paragraph{UI-VAERec} reconstructs a vector consisting of the concatenation
of a user row and item column.
It learns $\ptheta{\ric,\rcj|\boldz}$
and $\qphi{\boldz|\ric,\rcj}$.
This differs from the MFVA model with 
the MLP decoder proposed by
\cite{vanBaalen2016}, as a distribution on a 
single latent vector $\boldzij$ representing
the user-item pairing is being produced instead 
of having two distinct distributions on
$\boldui$ and $\boldvj$.

\subsection{Sampling the ratings for the \emph{UI} variants}

Training the \emph{UI-VAERec} would require
have very long epochs, as the number of training
datapoints would be the number of ratings.
To prevent problems related to excessive memory usage,
as one rating would be stored as a concatenation of
its user vector $\ric$ and item vector $\rcj$,
epochs have been implemented as random samplings 
of a fixed amount of the ratings.
The same sampling is performed in the test set.
