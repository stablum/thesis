\section{RealNVP}
\label{realnvp}
\cite{RealNVP} introduced a generative model which makes use of the
relationship between the probability distribution of a multivariate random
variable and a distribution of
its transformation, by the change of variable formula,
as explained in section \cite{density_transformed}.

This relationship is used to ease inference as in:
\begin{nalign}
p(\boldx) = p(\boldz|\boldx)\abs{\detDtr{\boldz}}^{-1}
\end{nalign}

In this case the transformation $\tr$ \emph{is}
the generator network.

\subsection{Transformation}

With the work of \cite{RealNVP} a very simple invertible function is presented
which has the following form:

\begin{nalign}
\left\{ 
    \begin{array}{ll}
    t(\boldz)_{1:d} &= \boldz_{1:d}
    \\
    t(\boldz)_{d+1:K} &= \boldz_{d+1:K}\odot \exp\left(s(\boldz_{1:d})\right) + a(\boldz_{1:d})
    \end{array}
\right.
\end{nalign}

    The inverse can be trivially obtained as:

\begin{nalign}
\left\{
    \begin{array}{ll}
    \boldz_{1:d} & = t(\boldz)_{1:d}\\
    \boldz_{d+1:K} &= \left( t(\boldz)_{1:d} - a(\boldz_{1:d}) \right) \underbrace{\oslash \exp(s(t(\boldz_{1:d})))}_{\odot \exp(-s(t(\boldz_{1:d})))}
    \end{array}
\right.
\end{nalign}

$s(\cdot)$ can be any dimensionality-preserving nonlinear function, such as a neural network with nonlinear activations. $a(\cdot)$ is an affine transformation.
In this work's implementation $d$ is set $d = K/2$. 

The main advantage of using such transformations is that the Jacobian matrix is triangular,
and its determinant ends up being $\exp\left(\sum_j s(\boldz_{1:d})_j \right)$ 


